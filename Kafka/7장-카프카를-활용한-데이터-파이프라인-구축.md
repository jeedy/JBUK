# 7장 카프카를 활용한 데이터 파이프라인 구축
#### 다루는 내용
- 카프카를 활용한 데이터 흐름도
- 파일비트를 이용한 메시지 전송 방법
- 나이파이를 이용한 컨슈머 설정과 메시지 가져오기 방법
- 실시간 분석을 위해 엘라스틱 서치에 메시지 저장 방법
- 키바나를 이용해 엘라스틱서치에 저장된 데이터 확인 방법


## 기본셋팅 (AWS를 사용한다는 가정, zookeeper kafka 를 이미 실행해 놨다면 생략가능)

### Root 권한주기
```sh
$ sudo passwd root
Changing password for user root.
New password:
Retype new password:
passwd: all authentication tokens updated successfully.
$ su root
Password:
```

### 주키퍼 실행
```
$ cd /usr/local/kafka_2.12-2.2.0

$ sudo bin/zookeeper-server-start.sh config/zookeeper.properties
```

### 카프카 실행

#### 1. 주키퍼 연결
/usr/local/kafka_2.12-2.2.0/config/server.properties:
```sh
zookeeper.connect=172.31.47.151:2181
```

#### 2. 카프카 실행
```sh
$ cd /usr/local/kafka_2.12-2.2.0

$ sudo bin/kafka-server-start.sh config/server.properties
```

#### 3. 토픽생성 및 확인
```bash
$ sudo bin/kafka-topics.sh --topic peter-log --partitions 1 --replication-factor 1 --create --bootstrap-server localhost:9092

$ sudo bin/kafka-topics.sh --list --bootstrap-server localhost:9092
> peter-log
```


## Filebeat 셋팅
엘라스틱에서 제공하고 있는 경량 데이터 수집기, 메시지를 생산해 낸 다음 그메시지를 카프카로 전송하는 역활을 하는 프로듀서.

[파일비트 설치 가이드](https://www.elastic.co/guide/en/beats/filebeat/7.3/setup-repositories.html)

### 1. 공용키 등록
> 공용키를 등록하는 이유는 패키지 다운로드 시 서로 간에 신뢰성 통신을 하기 위함.

```bash
$ rpm --import https://packages.elastic.co/GPG-KEY-elasticsearch
```

### 2. /etc/yum.repos.d 경로에 `elastic.repo` 파일생성
/etc/yum.repos.d/elastic.repo:
```bash
[elastic-7.x]
name=Elastic repository for 7.x packages
baseurl=https://artifacts.elastic.co/packages/7.x/yum
gpgcheck=1
gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
enabled=1
autorefresh=1
type=rpm-md
```

### 3. filebeat 설치
```bash
$ yum -y install filebeat
```

### 4. /etc/filebeat/filebeat.yml 파일 수정
/etc/filebeat/filebeat.yml:
```yaml
# ========== Filebeat prospectors ==========
# filebeat로 어떤 파일을 보낼지를 선택하는 부분
# /usr/local/kafka_2.12-2.2.0/logs/server.log 파일을 보내기 위한 설정
filebeat.inputs:
  - type: log
    enabled: true
    paths:
        - /usr/local/kafka_2.12-2.2.0/logs/server.log*
    multiline.pattern: '^\['
    multiline.negate: true
    multiline.match: after
    fields.pipeline: kafka-logs #파이브라인 아이디

# ========== Filebeat modules ==========
filebeat.config.modules:
  # Glob pattern for configuration loading
  enabled: true
  path: ${path.config}/modules.d/*.yml

  # Set to true to enable config reloading
  #  reload.enabled: false

  # Period on which files under path should be checked for changes
  #reload.period: 10s

# ========== Elasticsearch template setting ==========

        #setup.template.settings:
        #  index.number_of_shards: 1
  #index.codec: best_compression
  #_source.enabled: false

# ========== Kafka output ==========
#kafka의 프로듀서의 역할을 설정하는 부분이다.
output.kafka:
  hosts: ["172.31.47.151:9092"]
  topic: 'kafka-log'
  partition.round_robin:
    reachable_only: false

  required_acks: 1
  compression: gzip
  max_message_bytes: 1000000
```

### 5. filebeat 실행 및 상태확인
```bash
$ systemctl start filebeat.service

$ systemctl status filebeat.service

# 파일피트 중지
# systemctl stop filebeat.service
```

### 6. peter-log 토픽에 로그값이 들어오고 있는지 확인
```bash
$ /usr/local/kafka_2.12-2.2.0/bin/kafka-console-consumer.sh --bootstrap-server 172.31.47.151:9092 --topic peter-log --maxmessages
10 --from-beginning

... 
```


## Nifi
데이터 흐름을 정의하고, 정의된 흐름대로 자동으로 실행해주는 솔루션, 
데이터 흐름 기반으로 사용하기에 유용하며 웹 기반 인터페이스 제공.

카프카에 저장된 메시지를 가져오고 데이터 처리, 로그 분석을 위해 다른 어플리케이션으로 메시지를 전송하는 컨슈머 역활.

[나이파이 설치 가이드](https://nifi.apache.org/download.html)

### 1. 나이파이 설치
```bash
$ cd /usr/local

$ wget https://archive.apache.org/dist/nifi/1.8.0/nifi-1.8.0-bin.tar.gz

$ sudo tar -xzf nifi-1.8.0-bin.tar.gz
```

### 2. properties 수정
conf/nifi.properties:
```bash
(생략..)
nifi.web.http.host=172.31.47.151
(생략..)
nifi.cluster.is.node=false
(생략..)
nifi.zookeeper.connect.string=172.31.47.151:2181
(생략..)
```

### 3. systemd 에 nifi 등록
```bash
$ bin/nifi.sh install nifi
> Service nifi installed
```

### 4. nifi 실행
```bash
$ sudo bin/nifi.sh start

# 중지
# sudo bin/nifi.sh stop
```

### 5. nifi 상태확인
```bash
$ sudo bin/nifi.sh status
```

### 6. public IP로 나이파이 페이지 접속

http://13.209.69.119:8080/nifi

> nifi의 기본 port는 8080 이다.

`데이터 파이프연결 작업은 '카프카, 데이터플랫폼의 최강자' P275 참조하여 nifi 웹 페이지에서 작업`

### 7. 등록한 컨슈머 그룹이 잘 등록되었는지 확인
```bash
$ sudo bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list
> nifi-consumer001
```

컨슈머 그룹 상세보기
```bash
$ sudo bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group nifi-consumer001 --describe
```


## Elasticsearch
엘라스틱사의 분산형 Restful 검색 및 분석엔진, 전문 검색 질의를 이용해 원하는 데이터 분석을 빠르게 할 수 있는 애플리케이션.

[엘라스틱서치 설치 가이드](https://www.elastic.co/kr/downloads/elasticsearch)


### 1. 엘라스틱서치 Key 등록
```bash
$ rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch
```


### 2. /etc/yum.repos.d 에 저장소 등록
```bash
$ touch elasticsearch.repo
```


### 3. elasticsearch.repo 수정

/etc/yum.repos.d/elasticsearch.repo:
```
[elastic-7.x]
name=Elastic repository for 7.x packages
baseurl=https://artifacts.elastic.co/packages/7.x/yum
gpgcheck=1
gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
enabled=1
autorefresh=1
type=rpm-md
```


### 4. 엘라스틱서치 설치
```bash
$ yum -y install elasticsearch
```


### 5. /etc/elasticsearch/elasticsearch.yml 파일 수정

/etc/elasticsearch/elasticsearch.yml:
```yaml
#내용추가
path.data: /var/lib/elasticsearch
path.logs: /var/log/elasticsearch
network.host: 0.0.0.0
http.port: 9200
#transport.tcp.port: 9300
cluster.initial_master_nodes: node-1
```


### 5. 엘라스틱서치 실행 및 상태확인
```bash
$ systemctl start elasticsearch.service

$ systemctl status elasticsearch.service

# 중지
# systemctl stop elasticsearch.service
```

> elasticsearch의 기본 port는 9200이다.


`'카프카, 데이터플랫폼의 최강자'  P284 참조하여 nifi 웹 페이지에서 작업`